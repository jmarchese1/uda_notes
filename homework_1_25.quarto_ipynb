{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Homework 1\"\n",
        "author: \"Jason Marchese\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-location: left\n",
        "    self-contained: true\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "Professional wrestling, while not everyone's cup of tea, is big business. What started as a carnival act has turned into a global entertainment industry. \n",
        "Netflix recently started showing Monday Night Raw, a program from the biggest North American wrestling company,\n",
        " WWE -- this deal is reportedly worth \\$5 billion. Like any large entity, WWE is not without competition, drama, and scandal. \n",
        "\n",
        "## General Tips\n",
        "\n",
        "This is very much a step-by-step process. Don't go crazy trying to get everything done with as few lines as possible. \n",
        "Read the documentation for the AlphaVantage api! Carefully explore the pages from cagematch. \n",
        "There isn't a need to get too fancy with anything here -- just go with simple function and all should be good. \n",
        "Don't print comments, but use normal text for explanations.\n",
        "\n",
        "## Step 1\n",
        "\n",
        "In the `calls` folder, you'll find 4 text files -- these are transcripts from quarterly earnings calls. Read those files in \n",
        "(glob.glob will be very helpful here), with appropriate column names for ticker, quarter, and year columns; \n",
        "this should be done within a single function. Perform any data cleaning that you find necessary. \n"
      ],
      "id": "d1e0a20d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import glob as glob\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "\n",
        "#import data via glob\n",
        "data_files= glob.glob(\"C:/Users/jason/downloads/HD2023/unstructured data anayltics/calls/*\")\n",
        "print(data_files)\n",
        "\n",
        "def read_calls(data_files):\n",
        "    data_list = []\n",
        "    for file in data_files:\n",
        "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "            content = f.read()\n",
        "            file_name = file.split(\"/\")[-1]\n",
        "              # Read with UTF-8 encoding\n",
        "            ticker, quarter, year = file_name.replace(\".txt\", \"\").split(\"_\")\n",
        "            cleaned_content = \"\".join(content.split())\n",
        "\n",
        "            data_list.append({\n",
        "                \"ticker\": ticker,\n",
        "                \"quarter\": quarter,\n",
        "                \"year\": year,\n",
        "                \"content\": cleaned_content\n",
        "            })\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(data_list)\n",
        "\n",
        "    new_tickers = []\n",
        "    for ticker in df[\"ticker\"]:\n",
        "        new_ticker = re.sub(r\"[calls\\\\]\", \"\", ticker)\n",
        "        new_tickers.append(new_ticker)\n",
        "    \n",
        "    df[\"ticker\"] = new_tickers\n",
        "    \n",
        "    return df\n",
        "\n",
        "read_calls(data_files)\n"
      ],
      "id": "e0560636",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2\n",
        "\n",
        "Use the AlphaVantage api to get daily stock prices for WWE and related tickers for the last 5 years -- pay attention to your data.\n",
        " You cannot use any AlphaVantage packages (i.e., you can only use requests to grab the data). \n",
        " Tell me about the general trend that you are seeing. I don't care which viz package you use, \n",
        " but plotly is solid and plotnine is good for ggplot2 users.\n"
      ],
      "id": "0deac65a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests \n",
        "import seaborn as sns\n",
        "API_KEY = \"6E4YZCJEWJM383Q3\"  # Replace with your AlphaVantage API key\n",
        "\n",
        "# WWE and related companies (adjust if needed)\n",
        "tickers = [\"WWE\", \"EDR\", \"TKO\"] \n",
        "\n",
        "# Base URL for AlphaVantage\n",
        "BASE_URL = \"https://www.alphavantage.co/query\"\n",
        "\n",
        "# Dictionary to store stock data\n",
        "stock_data = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "\n",
        "    params = {\n",
        "        \"function\": \"TIME_SERIES_MONTHLY_ADJUSTED\",  #can only get 100 days of data without premium using the daily function\n",
        "        \"symbol\": ticker,\n",
        "        \"apikey\": API_KEY\n",
        "    }\n",
        "\n",
        "    response = requests.get(BASE_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"Monthly Adjusted Time Series\" in data:\n",
        "        df = pd.DataFrame.from_dict(data[\"Monthly Adjusted Time Series\"], orient=\"index\")\n",
        "        df = df.rename(columns={\n",
        "            \"1. open\": \"open\",\n",
        "            \"2. high\": \"high\",\n",
        "            \"3. low\": \"low\",\n",
        "            \"4. close\": \"close\",\n",
        "            \"5. adjusted close\": \"adjusted_close\",\n",
        "            \"6. volume\": \"volume\"\n",
        "        })\n",
        "\n",
        "        df.index = pd.to_datetime(df.index)  # Convert index to datetime\n",
        "        df = df.astype(float)  # Convert values to numeric\n",
        "        stock_data[ticker] = df  # Store DataFrame\n",
        "\n",
        "    else:\n",
        "        print(f\"Error fetching data for {ticker}: {data}\")\n",
        "\n",
        "\n",
        "stock_data[\"WWE\"].head()\n",
        "stock_data[\"WWE\"].tail()\n",
        "\n",
        "stock_data[\"EDR\"].head()\n",
        "stock_data[\"EDR\"].tail()\n",
        "\n",
        "stock_data[\"TKO\"].head()\n",
        "stock_data[\"TKO\"].tail()\n",
        "#since wwe data does not go up until present taking the last 5 years of wwe data and overlaying it to the corresponding years in other tickers.\n",
        "\n",
        "last_5_years_WWE = stock_data[\"WWE\"].loc[pd.Timestamp(\"2023-09-11\"):pd.Timestamp(\"2019-01-01\")]\n",
        "last_5_years_EDR = stock_data[\"EDR\"].loc[pd.Timestamp(\"2025-02-03\"):pd.Timestamp(\"2021-05-28\")]\n",
        "last_5_years_TKO = stock_data[\"TKO\"].loc[pd.Timestamp(\"2025-02-03\"):pd.Timestamp(\"2023-10-31\")]\n",
        "\n",
        "stock_data[\"WWE\"].head()\n",
        "stock_data[\"WWE\"].tail()\n",
        "\n",
        "last_5_years_WWE.head()\n",
        "last_5_years_WWE.tail()\n",
        "stock_data[\"TKO\"].head()\n",
        "stock_data[\"TKO\"].tail()\n",
        "\n",
        "\n",
        "#plotting the data \n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.lineplot(data=last_5_years_WWE[\"adjusted_close\"], label=\"WWE\", lw = 3)\n",
        "sns.lineplot(data=last_5_years_EDR[\"adjusted_close\"], label=\"EDR\", lw = 3)\n",
        "sns.lineplot(data=last_5_years_TKO[\"adjusted_close\"], label=\"TKO\", lw = 3)\n",
        "plt.title(\"Stock Prices for WWE and Related Companies\")\n",
        "plt.ylabel(\"Adjusted Close Price\")\n",
        "plt.xlabel(\"Date\")\n",
        "\n",
        "#tko is the mother company of the wwe and ufc.. the ufc stock ticker is not available after 2023 so TKO is the\n",
        "#closest thing to it. \n",
        "\n",
        "#EDR is the majority holder of TKO so it is also included in the plot.\n",
        "\n",
        "#Theres a strong uptrend in the WWE stock which continues in the past year with\n",
        "#TKO which aquired the WWE "
      ],
      "id": "078eb1c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3\n",
        "\n",
        "Just like every other nerdy hobby, professional wrestling draws dedicated fans. Wrestling fans often go to cagematch.net to leave reviews for matches, shows, \n",
        "and wrestlers. The following link contains the top 100 matches on cagematch: https://www.cagematch.net/?id=111&view=statistics\n",
        "\n",
        "* What is the correlation between WON ratings and cagematch ratings?\n",
        "\n",
        "** Which wrestler has the most matches in the top 100?\n",
        "\n",
        "*** Which promotion has the most matches in the top 100? \n",
        "\n",
        "**** What is each promotion's average WON rating?\n",
        "\n",
        "***** Select any single match and get the comments and ratings for that match into a data frame.\n"
      ],
      "id": "dca139ee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import regex as re\n",
        "\n",
        "url = \"https://www.cagematch.net/?id=111&view=statistics\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "table = soup.find(\"table\")\n",
        "\n",
        "rows = table.find_all(\"tr\")[1:]\n",
        "\n",
        "match_data = []\n",
        "\n",
        "for row in rows:\n",
        "  columns = row.find_all(\"td\")\n",
        "  if len(columns) < 8:\n",
        "    continue\n",
        "\n",
        "  rank = columns[0].text.strip()  # Match rank\n",
        "  date = columns[1].text.strip()  # Match date\n",
        "  promotion = columns[2].find(\"img\")[\"alt\"].strip() if columns[2].find(\"img\") else \"Unknown\"  # Wrestling promotion\n",
        "  match_name = columns[3].text.strip()  # Wrestlers involved\n",
        "  WON = columns[4].text.strip() # WON rating\n",
        "  rating = columns[6].text.strip()  # Cagematch rating\n",
        "  votes = columns[7].text.strip()  # Number of votes\n",
        "\n",
        "  match_data.append({\n",
        "      \"Rank\": rank,\n",
        "      \"Date\": date,\n",
        "      \"Promotion\": promotion,\n",
        "      \"Match\": match_name,\n",
        "      \"Rating\": rating,\n",
        "      \"Votes\": votes,\n",
        "      \"WON rating\" : WON\n",
        "    })\n",
        "\n",
        "\n",
        "df2 = pd.DataFrame(match_data)\n",
        "df2\n",
        "\n",
        "def won_rating(WON):\n",
        "    star_mapping = {\n",
        "        \"****\": 4,\n",
        "        \"****1/4\" : 4.25,\n",
        "        \"****1/2\": 4.5,\n",
        "        \"****3/4\": 4.75,\n",
        "        \"*****\" : 5,\n",
        "        \"*****1/4\": 5.25,\n",
        "        \"*****1/2\": 5.5,\n",
        "        \"*****3/4\": 5.75,\n",
        "        \"******\": 6,\n",
        "        \"******1/4\": 6.25,\n",
        "        \"******1/2\": 6.5,\n",
        "        \"******3/4\": 6.75,\n",
        "        \"*******\": 7\n",
        "    }\n",
        "\n",
        "    return star_mapping.get(WON, None)\n",
        "\n",
        "df2[\"WON rating\"] = df2[\"WON rating\"].apply(won_rating)\n",
        "\n",
        "\n",
        "\n",
        "df2.head()\n",
        "\n",
        "\n",
        "#what is the correlation between WON ratings and cagematch ratings\n",
        "won_ratings = df2[\"WON rating\"]\n",
        "cagematch_ratings = df2[\"Rating\"]\n",
        "correlation = won_ratings.corr(cagematch_ratings)\n",
        "correlation #the correlation is 0.35\n",
        "\n",
        "#which wrestler has the most matches in the top 100\n",
        "wrestlers = df2[\"Match\"]\n",
        "\n",
        "wrestler_names = []\n",
        "for match in df2[\"Match\"]:\n",
        "    teams = match.split(\" vs. \")\n",
        "\n",
        "    for team in teams:\n",
        "        wrestlers = re.split(r\" & |, \", team)\n",
        "        wrestler_names.extend(wrestlers)\n",
        "\n",
        "wrestler_counts = pd.Series(wrestler_names).value_counts()\n",
        "wrestler_counts.head(1) #kenny omega has the most matches in the top 100 with 15 matches\n",
        "\n",
        "\n",
        "#which promotion has the most matches in the top 100\n",
        "promotions = df2[\"Promotion\"].value_counts().head(1)\n",
        "promotions\n",
        "#new japan pro wrestling has the most matches in the top 100 with 34\n",
        "\n",
        "#what is each promotion's average WON rating\n",
        "df2.groupby(\"Promotion\")[\"WON rating\"].mean().sort_values(ascending=False)  \n",
        "\n",
        "\n",
        "#getting the comments and ratings for a single match\n",
        "single_match_url = \"https://www.cagematch.net/?id=111&nr=8034&page=99\"\n",
        "single_match_response = requests.get(single_match_url)\n",
        "single_match_soup = BeautifulSoup(single_match_response.text, \"html.parser\")\n",
        "\n",
        "\n",
        "# Extract all individual comments inside the section\n",
        "comment_boxes = single_match_soup.find_all(\"div\", class_=\"Comment\")\n",
        "comment_boxes\n",
        "\n",
        "#creating an empty list to store the comments\n",
        "comments_data = []\n",
        "#extracting the comments by using a for loop to iterate through the comment boxes\n",
        "for comment in comment_boxes:\n",
        "  comment_text = comment.find(\"div\", class_=\"CommentContents\").text.strip()\n",
        "  comments_data.append({\"Comment\": comment_text})\n",
        "\n",
        "#since I appended the comments as a dictionary the col name is already defined \n",
        "#so I can just convert the list of dictionaries to a dataframe\n",
        "comments_ratings_df = pd.DataFrame(comments_data)\n",
        "\n",
        "# Extract ratings from comments\n",
        "ratings = []\n",
        "for comment in comments_ratings_df[\"Comment\"]:\n",
        "    rating = re.findall(r\"(\\d+)\", comment)\n",
        "    if len(rating) >= 2:  # Ensure at least two numbers exist\n",
        "        ratings.append(int(rating[0]))  # Convert to integers and store as tuple\n",
        "    else:\n",
        "        ratings.append(None)\n",
        "    \n",
        "comments_ratings_df[\"Rating\"] = ratings\n",
        "\n",
        "new_comments = []\n",
        "for comment in comments_ratings_df[\"Comment\"]:\n",
        "    if \"]\" in comment:\n",
        "        no_rating = comment.split(\"]\")[1]\n",
        "        new_comments.append(no_rating)\n",
        "    else:\n",
        "        no_rating = comment\n",
        "        new_comments.append(no_rating)\n",
        "\n",
        "comments_ratings_df[\"Comment\"] = new_comments \n",
        "\n",
        "comments_ratings_df"
      ],
      "id": "1ad86f3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4\n",
        "\n",
        "You can't have matches without wrestlers. The following link contains the top 100 wrestlers, according to cagematch: https://www.cagematch.net/?id=2&view=statistics\n",
        "\n",
        "*** Of the top 100, who has wrestled the most matches?\n",
        "\n",
        "***** Of the top 100, which wrestler has the best win/loss?\n"
      ],
      "id": "87e8d758"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "wrestlers_url = \"https://www.cagematch.net/?id=2&view=statistics\"\n",
        "\n",
        "wrestlers_response = requests.get(wrestlers_url)\n",
        "\n",
        "wrestlers_soup =BeautifulSoup(wrestlers_response.text, \"html.parser\")\n",
        "\n",
        "wrestlers_table = wrestlers_soup.find(\"table\")\n",
        "\n",
        "wrestlers_rows = wrestlers_table.find_all(\"tr\")[1:]\n",
        "\n",
        "wrestlers_data = []\n",
        "\n",
        "for row in wrestlers_rows:\n",
        "    columns = row.find_all(\"td\")\n",
        "    if len(columns) < 8:\n",
        "        continue\n",
        "\n",
        "    rank = columns[0].text.strip()  # Wrestler rank\n",
        "    Gimmick = columns[1].text.strip()  # Wrestler name\n",
        "    Birthplace = columns[2].text.strip()  # Number of matches\n",
        "    Height = columns[3].text.strip()  # Number of wins\n",
        "    Weight = columns[4].text.strip()  # Number of losses\n",
        "    Promotion = columns[5].text.strip()  # Number of draws\n",
        "    Rating = columns[6].text.strip()  # Win percentage\n",
        "    Votes = columns[7].text.strip()  # Cagematch rating\n",
        "\n",
        "    wrestlers_data.append({\n",
        "        \"rank\": rank,\n",
        "        \"Gimmick\": Gimmick,\n",
        "        \"Birthplace\": Birthplace,\n",
        "        \"Height\": Height,\n",
        "        \"Weight\": Weight,\n",
        "        \"Promotion\": Promotion,\n",
        "        \"Rating\": Rating,\n",
        "        \"Votes\": Votes\n",
        "    })\n",
        "\n",
        "df3 = pd.DataFrame(wrestlers_data)\n",
        "df3.head()\n",
        "\n",
        "#which wrestler has wrestled the most matches\n",
        "link_stats = \"https://www.cagematch.net/?id=111&view=matchstatistics\"\n",
        "stats_response = requests.get(link_stats)\n",
        "stats_soup = BeautifulSoup(stats_response.text, \"html.parser\")\n",
        "stats_content = stats_soup.select('div.TableContents tr td')\n",
        "stats_content\n",
        "\n",
        "stuff = [stats_content[x].text for x in range(0, len(stats_content))]\n",
        "print(stuff)\n",
        "\n",
        "colnames = stuff[:9]\n",
        "print(colnames)\n",
        "\n",
        "last_content = stuff[9:]\n",
        "print(last_content)\n",
        "\n",
        "rows = []\n",
        "for i in range(0, len(last_content), 9):\n",
        "    rows.append(last_content[i:i+9])\n",
        "\n",
        "print(rows)\n",
        "\n",
        "win_loss_df = pd.DataFrame(rows, columns=colnames)\n",
        "win_loss_df\n",
        "\n",
        "#wrestler with the best win/loss\n",
        "import numpy as np\n",
        "win_loss_df.fillna(0, inplace = True)\n",
        "win_loss_df[\"Wins\"] = pd.to_numeric(win_loss_df[\"Wins\"], errors = \"coerce\")\n",
        "win_loss_df[\"Losses\"] = pd.to_numeric(win_loss_df[\"Losses\"], errors = \"coerce\")\n",
        "win_loss_df[(win_loss_df[\"Losses\"] == 0) & (win_loss_df[\"Wins\"] > 0)].sort_values(\"% W\", ascending = True).head(10)\n",
        "\n",
        "win_loss_df\n",
        "#there are 9 wrestlers with a 100% win rate\n",
        "\n",
        "#finding which wrestler has the most career matches\n",
        "link_matches = \"https://www.cagematch.net/?id=2&view=statistics\"\n",
        "req = requests.get(link_matches)\n",
        "soup = BeautifulSoup(req.text, \"html.parser\")\n",
        "\n",
        "links = soup.select('div.TableContents tr td a')\n",
        "links\n",
        "\n",
        "wrestler_links = [link['href'] for link in links]\n",
        "wrestler_links\n",
        "\n",
        "BASE_URL = \"https://www.cagematch.net/\"\n",
        "\n",
        "\n",
        "\n",
        "full_links = [BASE_URL + link for link in wrestler_links]\n",
        "full_links\n",
        "\n",
        "\n",
        "stats_pages = []\n",
        "for link in full_links:\n",
        "    next_link = link.split(\"&gimmick\")[0] + \"&page=22\"\n",
        "    stats_pages.append(next_link)\n",
        "stats_pages\n",
        "\n",
        "\n",
        "most_matches = []\n",
        "for i in stats_pages:\n",
        "    req = requests.get(i)\n",
        "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
        "    stats = soup.select(\"div.HeaderBox h1.TextHeader, div.InformationBoxContents\")\n",
        "\n",
        "    most_matches.append([stat.get_text(strip = True) for stat in stats])\n",
        "\n",
        "most_matches\n",
        "\n",
        "most_matches_df = pd.DataFrame(most_matches, columns = [\"Name\", \"Matches\", \"Wins\", \"Losses\", \"Draws\"])\n",
        "most_matches_df.head()\n",
        "\n",
        "most_matches_df[\"Matches\"] = pd.to_numeric(most_matches_df[\"Matches\"], errors=\"coerce\")\n",
        "\n",
        "most_matches_df[\"Matches\"].argmax()\n",
        "print(f\"the wrestler with the most matches is {most_matches_df[\"Name\"][155]} with {most_matches_df[\"Matches\"][155]} matches\")"
      ],
      "id": "3aa31e4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5\n",
        "\n",
        "With all of this work out of the way, we can start getting down to strategy.\n",
        "\n",
        "First, what talent should WWE pursue? Advise carefully.\n"
      ],
      "id": "ff8d8cff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#going to create a new variable country and then find the average rating and won rating from \n",
        "#wrestlers of from the same country.\n",
        "df3.head()\n",
        "#getting the last word in birth place to get the country\n",
        "df3[\"Country\"] = df3[\"Birthplace\"].str.split().str[-1]\n",
        "type(df3[\"Rating\"][1])\n",
        "df3[\"Rating\"] = pd.to_numeric(df3[\"Rating\"], errors = \"coerce\")\n",
        "df3.groupby(\"Country\")[\"Rating\"].mean().sort_values(ascending = False)\n",
        "\n",
        "#creating a swarmplot to view the amout of wrestlers from each country and their average rating\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.swarmplot(data = df3, x = \"Country\", y = \"Rating\", hue = \"Country\", palette = \"viridis\", dodge = False)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title(\"Japan and the US have the highest rated wrestlers\", fontdict = {\"fontsize\" : 15, \"weight\" : \"bold\"})"
      ],
      "id": "c60c239d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on my analysis, WWE should pursue wrestlers from Japan and the US as they have the highest average ratings. Not only does this mean that they are the most skilled wrestlers, it also suggests Japan and the United States has the largest fan base for the WWE and they would be more likely to tune in to watch their favorite wrestlers from thier country.\n",
        "\n",
        "Second, reconcile what you found in steps 3 and 4 with Netflix's relationship with WWE. Use the data from the following page to help make your case: https://wrestlenomics.com/tv-ratings/\n",
        "\n",
        "Since WWE RAW made its netfilx debt viewiership saw a massive spike but fell off in the following weeks. This is not all bad though because the WWE reached a new audience and it expected that the WWE isnt for everyone. Now the WWE has a massive new opportunity to try to retain using strategies like signing more wrestlers from the US and Japan.\n",
        "\n",
        "\n",
        "Third, do you have any further recommendations for WWE?\n",
        "\n",
        "recomendations: I think I would be a good idea for the WWE to prioritize US and Japan wrestlers \n",
        "where the most fans reside and try to primary sign talent from those countries. I also think in order to grow the sport it would be logical to sign a few wrestlers from other countries without a strong wrestling presence to try and grow the sport in those countries. If the WWE finds that the wrestlers from those countries gain traction they could then sign more talent from those countries.\n",
        "\n",
        " A goood example of this can be seen in the swarm plot above where Osterrich has a high average rating but only 1 wrestler from that country. This could be a good opportunity for the WWE to sign more wrestlers from Osterrich and grow the sport in that country. If it becomes a trend that wrestlers from Osterrich are popular then the WWE could sign more talent from that country. Another country that presents a similar opportunity is Belgien.\n"
      ],
      "id": "1a74a96a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\jason\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}